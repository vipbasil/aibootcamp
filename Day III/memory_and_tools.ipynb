{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5c5bbdd"
      },
      "source": [
        "# üß† CrewAI: Multi-Agent Bidding Example\n",
        "\n",
        "In this notebook, you'll define a team of agents who will **bid** on tasks based on their roles and assign the most suitable agent to each task dynamically.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19eeeee4"
      },
      "source": [
        "## ‚öôÔ∏è Step 1: Environment Setup\n",
        "This installs and runs the `ollama` backend and exposes the service via localtunnel tunnel. Make sure to:\n",
        "- Restart the runtime if needed\n",
        "- Use the ngrok alternative (if Cloudflare is blocked or throttled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssm5RJKID82Z"
      },
      "outputs": [],
      "source": [
        "%pip install ollama chromadb\n",
        "%pip install colab-xterm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è System Info Tools (Optional)\n",
        "\n",
        "Installs utilities (`pciutils`, `lshw`) to inspect hardware specs ‚Äî useful for checking GPU/CPU availability in Colab or local runtime.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RimdapHHa7b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install pciutils lshw"
      ],
      "metadata": {
        "id": "eBW3P8YuECqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Ollama Installation\n",
        "\n",
        "Downloads and installs Ollama via the official shell script ‚Äî run this once per environment setup."
      ],
      "metadata": {
        "id": "CsSHIndzbDOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "AwFE191pEGaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5285c8c4"
      },
      "source": [
        "## üîß Step 2: Programmatic Model Management and Server Initialization\n",
        "\n",
        "In this section, we:\n",
        "- Import the required libraries for managing subprocesses, HTTP requests, and multithreading\n",
        "- Start the Ollama server programmatically using a background thread\n",
        "- Pull the required models (`deepseek-r1:7b`, `llama3`) using `ollama pull`\n",
        "- Optionally include fallback to a smaller model (`deepseek-r1:1.5b`)\n",
        "- Confirm the list of available models and test that the local Ollama server is running at `localhost:11434`\n",
        "\n",
        "üìå **Why it matters**: This sets up your local model infrastructure for agent interaction. You'll later reference `localhost:11434` in your agent definitions to connect to these models.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "import threading\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "cqoaeOpaEZZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Launching the Ollama Server in Background\n",
        "\n",
        "Before using any model, we need to start the **Ollama inference server**, which listens by default on `localhost:11434`.\n",
        "\n",
        "This snippet:\n",
        "- Defines a Python function `run_ollama()` that launches `ollama serve`\n",
        "- Starts it in a **background thread**, so the notebook remains interactive\n",
        "- Allows the server to stay active without blocking further cells\n",
        "\n",
        "üõ†Ô∏è **Note**: You only need to run this once per session. If you restart your Colab, re-run this cell before using any models.\n"
      ],
      "metadata": {
        "id": "QRLABB5HZZo7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f370227"
      },
      "outputs": [],
      "source": [
        "# Start the Ollama server\n",
        "def run_ollama():\n",
        "  subprocess.Popen([\"ollama\", \"serve\"])\n",
        "thread = threading.Thread(target=run_ollama)\n",
        "thread.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì• Pulling Models\n",
        "\n",
        "We download pre-trained models from the Ollama registry:\n",
        "- `deepseek-r1:7b` ‚Äì reasoning & code\n",
        "- `llama3` ‚Äì general-purpose assistant"
      ],
      "metadata": {
        "id": "QSnmd7ryZqNM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6723baed"
      },
      "outputs": [],
      "source": [
        "# Download the deepseek-r1:7b distilled model\n",
        "!ollama pull deepseek-r1:7b\n",
        "#!ollama pull llama3\n",
        "!ollama pull deepseek-coder:6.7b\n",
        "# If this doesn't work, you can uncomment the below code to download a smaller model- deepseek-r1:1.5b\n",
        "# !ollama pull deepseek-r1:1.5b"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ü™∂ Pulling Lightweight SLMs\n",
        "\n",
        "These small models are ideal for fast local agents and low-resource environments:\n",
        "- `phi3:mini`, `tinyllama` ‚Äì ultra-small general models\n",
        "- `gemma:2b` ‚Äì Google's compact chat model\n",
        "- `deepseek-r1:1.5b` ‚Äì distilled reasoning model"
      ],
      "metadata": {
        "id": "0eZ8XjjMZ3ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!ollama pull phi3:mini\n",
        "#!ollama pull tinyllama\n",
        "#!ollama pull gemma:2b\n",
        "!ollama pull deepseek-r1:1.5b"
      ],
      "metadata": {
        "id": "rbNtHtlRHlWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß† Downloading Embedding Models\n",
        "\n",
        "To enable **Retrieval-Augmented Generation (RAG)**, we need to convert documents and queries into **vector embeddings**. These vectors help the agent understand meaning and similarity between texts.\n",
        "\n",
        "The following commands pull different embedding models using **Ollama**, which we‚Äôll use later to build a vectorstore for document search.\n",
        "\n"
      ],
      "metadata": {
        "id": "OfBudA6qjhdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull mxbai-embed-large:latest\n",
        "#!ollama pull nomic-embed-text\n",
        "#!ollama pull all-minilm"
      ],
      "metadata": {
        "id": "zj0Pw84rUhNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîå Test Ollama Server\n",
        "\n",
        "Sends a test request to verify the Ollama server is running on `localhost:11434`."
      ],
      "metadata": {
        "id": "SLHS7WUwaMNk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aae1987"
      },
      "outputs": [],
      "source": [
        "!curl http://127.0.0.1:11434"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìÑ Check Installed Models\n",
        "\n",
        "Lists all models currently downloaded and available in your local Ollama environment."
      ],
      "metadata": {
        "id": "V5JaeB4YaAlx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9809d934"
      },
      "outputs": [],
      "source": [
        "!ollama list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìö Embedding Documents into a Vector Store\n",
        "\n",
        "In this step, we convert a list of simple documents (facts about llamas) into **vector embeddings** and store them in a searchable database using `Chroma`.\n",
        "\n",
        "We'll use **Ollama** to generate embeddings with a local model (`mxbai-embed-large`), and **ChromaDB** to store and later retrieve these vectors.\n"
      ],
      "metadata": {
        "id": "kOf6SaU_mwje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "import chromadb\n",
        "\n",
        "# üß† Agent roles + process knowledge + product information + pricing\n",
        "documents = [\n",
        "  # Agent definitions\n",
        "  \"The SalesRep is responsible for initiating conversations with customers, discovering their needs, and building trust through dialogue.\",\n",
        "  \"The ProductRecommender analyzes customer preferences and suggests the most appropriate products from available stock.\",\n",
        "  \"The QuotationAgent prepares clear, itemized quotes that include discounts, taxes, and delivery options.\",\n",
        "  \"The CRMUpdater logs customer details, preferences, and quote history into the CRM for future reference and follow-ups.\",\n",
        "\n",
        "  # Retail process knowledge\n",
        "  \"In retail, a good sales conversation starts by understanding the customer's needs through qualifying questions.\",\n",
        "  \"Product recommendations should be based on customer lifestyle, preferences, and intended use.\",\n",
        "  \"A quote must include item breakdowns, applied discounts, taxes, and any relevant shipping or warranty info.\",\n",
        "  \"CRM systems are essential for tracking interactions, updating contact info, and managing follow-up tasks.\",\n",
        "  \"Follow-up messages after a quote can increase conversion rates by over 60%, especially if personalized.\",\n",
        "  \"New customers are often offered a 10% discount as part of welcome campaigns in retail.\",\n",
        "  \"Retail agents often work as a team: a sales rep engages the client, a recommender suggests items, and another agent prepares the invoice.\",\n",
        "\n",
        "  # Product info + pricing\n",
        "  \"The MountainFlow 45L Backpack is waterproof, lightweight, and perfect for 2‚Äì5 day hikes or urban travel. Price: $89.99\",\n",
        "  \"The CloudShell Rain Jacket is windproof, breathable, and designed for sudden weather changes. Price: $129.00\",\n",
        "  \"PowerCore Mini Charger provides 5200mAh backup power, USB-C support, and airplane-safe batteries. Price: $29.95\",\n",
        "  \"The TrailMax Pro Hiking Shoes are made for long treks, with ankle support and anti-slip soles. Price: $149.00\",\n",
        "  \"The Nomad Filter Bottle purifies water from natural sources and holds up to 1L of liquid. Price: $49.50\",\n",
        "  \"All travel gear products come with a 2-year warranty and optional 24h delivery upgrade.\",\n",
        "  \"The Essentials Travel Bundle includes a backpack, charger, and rain jacket at 15% off bundled price. Bundle Price: $215.00\",\n",
        "  \"Each product supports customer reviews and is frequently recommended by outdoor travel influencers.\"\n",
        "]\n",
        "\n",
        "client = chromadb.Client()\n",
        "collection = client.get_or_create_collection(name=\"retail_knowledge\")\n",
        "\n",
        "# Store each document in a vector embedding database\n",
        "for i, d in enumerate(documents):\n",
        "  response = ollama.embed(model=\"mxbai-embed-large\", input=d)\n",
        "  embeddings = response[\"embeddings\"]\n",
        "  collection.add(\n",
        "    ids=[str(i)],\n",
        "    embeddings=embeddings,\n",
        "    documents=[d]\n",
        "  )\n"
      ],
      "metadata": {
        "id": "xmqFl_vWklVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîç Querying the Vector Store with a Prompt\n",
        "\n",
        "Now that we've stored our documents as embeddings, we can perform **semantic search** using a new input prompt.\n",
        "\n",
        "This step simulates how an agent might retrieve relevant knowledge using **Retrieval-Augmented Generation (RAG)**.\n"
      ],
      "metadata": {
        "id": "jYAeHihFm73i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# an example input\n",
        "prompt = \"What animals are llamas related to?\"\n",
        "\n",
        "# generate an embedding for the input and retrieve the most relevant doc\n",
        "response = ollama.embed(\n",
        "  model=\"mxbai-embed-large\",\n",
        "  input=prompt\n",
        ")\n",
        "print (response)\n",
        "results = collection.query(\n",
        "  query_embeddings=response[\"embeddings\"],\n",
        "  n_results=1\n",
        ")\n",
        "data = results['documents'][0][0]\n",
        "print (data)"
      ],
      "metadata": {
        "id": "0UlI4s3dkyYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "504891b1"
      },
      "source": [
        "# üß† Starting the CrewAI Section\n",
        "\n",
        "##Now we define agents using CrewAI, connected to our locally running Ollama models.  \n",
        "##This enables multi-agent workflows powered by lightweight, self-hosted LLMs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f26b8d0b"
      },
      "outputs": [],
      "source": [
        "# @title üë®‚Äçü¶Ø Run this cell to hide all warnings (optional)\n",
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# To avoid the restart session warning in Colab, exclude the PIL and\n",
        "# pydevd_plugins packages from being imported. This is fine because\n",
        "# we didn't execute the code in the kernel session afterward.\n",
        "\n",
        "# import sys\n",
        "# sys.modules.pop('PIL', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ca86609"
      },
      "outputs": [],
      "source": [
        "# @title ‚¨áÔ∏è Install project dependencies by running this cell\n",
        "%pip install git+https://github.com/joaomdmoura/crewAI.git --quiet\n",
        "%pip install crewai_tools langchain_groq langchain_anthropic langchain_community cohere --quiet\n",
        "print(\"---\")\n",
        "%pip show crewAI crewai_tools langchain_groq langchain_anthropic langchain_community cohere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "577d53c4"
      },
      "source": [
        "## üß© Step 3: CrewAI Integration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88866d05"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "#from crewai import Agent, Task, Crew, Process\n",
        "#from textwrap import dedent\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb30a521"
      },
      "source": [
        "## Define Agents\n",
        "In CrewAI, agents are autonomous entities designed to perform specific roles and achieve particular goals. Each agent uses a language model (LLM) and may have specialized tools to help execute tasks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üïµüèª Define your agents\n",
        "\n",
        "from crewai import Agent\n",
        "from textwrap import dedent\n",
        "# Define LLM (OpenAI used here; replace as needed)\n",
        "from crewai import LLM\n",
        "\n",
        "llm = LLM(model=\"ollama/deepseek-r1:7b\", base_url=\"http://127.0.0.1:11434\")\n"
      ],
      "metadata": {
        "id": "WM2l-5VqZqYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "# Importing crewAI tools\n",
        "from crewai_tools import (\n",
        "    DirectoryReadTool,\n",
        "    FileReadTool,\n",
        "    SerperDevTool,\n",
        "    WebsiteSearchTool\n",
        ")\n"
      ],
      "metadata": {
        "id": "69x9s5W1fC4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_tool = DirectoryReadTool(directory='./blog-posts')\n",
        "file_tool = FileReadTool()\n",
        "search_tool = SerperDevTool()\n",
        "web_rag_tool = WebsiteSearchTool()"
      ],
      "metadata": {
        "id": "ldP3316AfGt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_specs = {\n",
        "    \"SalesRep\": {\n",
        "        \"role\": \"SalesRep\",\n",
        "        \"goal\": \"Engage with customer inquiries and identify their needs.\",\n",
        "        \"backstory\": \"Retail sales agent trained in conversational selling and client discovery.\",\n",
        "        \"llm\": \"ollama/deepseek-r1:7b\",\n",
        "        \"knowledge\": [\n",
        "      \"Our store specializes in travel and outdoor gear. The most popular customer profiles are: hikers, digital nomads, and weekend travelers.\",\n",
        "      \"Sales typically start with customer inquiries via chat, Telegram, or in-store. The SalesRep must open the conversation and guide the customer naturally.\",\n",
        "      \"The SalesRep should ask qualifying questions like: 'What kind of trip are you planning?', 'Do you already own any of this gear?', and 'Are you traveling light or packing for longer stays?'\",\n",
        "      \"First-time customers automatically receive a 10% discount on any order over $100.\",\n",
        "      \"SalesReps should avoid recommending products directly ‚Äî instead, they pass the customer's preferences to the ProductRecommender agent.\",\n",
        "      \"Our communication style is friendly, conversational, and helpful ‚Äî we prioritize rapport over hard selling.\",\n",
        "      \"When ending a conversation, the SalesRep should pass the lead along with notes to the next agent, and optionally schedule a follow-up.\"\n",
        "    ]\n",
        "    },\n",
        "    \"ProductRecommender\": {\n",
        "        \"role\": \"ProductRecommender\",\n",
        "        \"goal\": \"Suggest suitable products based on customer preferences.\",\n",
        "        \"backstory\": \"Expert in matching customer needs with available stock.\",\n",
        "        \"llm\": \"ollama/deepseek-coder:6.7b\",\n",
        "        \"knowledge\": [\n",
        "      \"Available products and prices:\",\n",
        "      \"- MountainFlow 45L Backpack ‚Äì waterproof, lightweight, ideal for 2‚Äì5 day trips. Price: $89.99\",\n",
        "      \"- CloudShell Rain Jacket ‚Äì windproof, breathable, for unpredictable weather. Price: $129.00\",\n",
        "      \"- PowerCore Mini Charger ‚Äì 5200mAh, USB-C, compact and TSA-compliant. Price: $29.95\",\n",
        "      \"- TrailMax Pro Hiking Shoes ‚Äì ankle support, anti-slip sole. Price: $149.00\",\n",
        "      \"- Nomad Filter Bottle ‚Äì filters water, 1L capacity. Price: $49.50\",\n",
        "      \"- Essentials Travel Bundle: includes backpack, charger, and rain jacket at 15% off. Bundle Price: $215.00\",\n",
        "      \"Recommendation criteria:\",\n",
        "      \"- Consider customer needs: weather, terrain, travel duration, weight preferences, and destination.\",\n",
        "      \"- Recommend in groups: for example, backpack + charger + rain jacket.\",\n",
        "      \"- Mention reviews and top-rated gear when relevant.\",\n",
        "      \"- Use value language: 'lightweight', 'durable', 'fast-charging', 'waterproof', etc.\",\n",
        "      \"All recommendations must be justified and mapped back to the customer's stated intent or preference.\"\n",
        "    ]\n",
        "    },\n",
        "    \"QuotationAgent\": {\n",
        "        \"role\": \"QuotationAgent\",\n",
        "        \"goal\": \"Prepare detailed and accurate price quotes.\",\n",
        "        \"backstory\": \"Skilled in pricing logic, tax rules, and markdown strategies.\",\n",
        "        \"llm\": \"ollama/deepseek-r1:7b\",\n",
        "        \"knowledge\": [\n",
        "      \"Quotes must include:\",\n",
        "      \"- List of products with unit prices and quantities.\",\n",
        "      \"- Subtotal before discounts.\",\n",
        "      \"- Discounts (if applicable).\",\n",
        "      \"- Tax (8% standard).\",\n",
        "      \"- Shipping fee (if applicable).\",\n",
        "      \"- Final total with everything included.\",\n",
        "      \"Discount policy:\",\n",
        "      \"- 10% off for new customers (first purchase only, over $100).\",\n",
        "      \"- 15% off for Essentials Bundle (automatically applied).\",\n",
        "      \"Shipping options:\",\n",
        "      \"- Standard shipping (3‚Äì5 business days): free for orders over $150.\",\n",
        "      \"- Express delivery (24 hours): flat rate of $19.99.\",\n",
        "      \"Price references (USD):\",\n",
        "      \"- Backpack: $89.99\",\n",
        "      \"- Jacket: $129.00\",\n",
        "      \"- Charger: $29.95\",\n",
        "      \"- Shoes: $149.00\",\n",
        "      \"- Bottle: $49.50\",\n",
        "      \"- Bundle: $215.00\",\n",
        "      \"All prices should be calculated to 2 decimal places. Output should be clean and suitable for PDF or email formatting.\",\n",
        "      \"Mention the validity of the quote (default: 7 days) and include a reference ID.\"\n",
        "    ]\n",
        "    },\n",
        "    \"CRMUpdater\": {\n",
        "        \"role\": \"CRMUpdater\",\n",
        "        \"goal\": \"Log sales interactions and outcomes into the CRM.\",\n",
        "        \"backstory\": \"Ensures customer data is updated after each interaction.\",\n",
        "        \"llm\": \"ollama/deepseek-r1:7b\",\n",
        "        \"knowledge\": [\n",
        "      \"A CRM log should include the following fields:\",\n",
        "      \"- Customer name\",\n",
        "      \"- Contact method (Telegram handle, email)\",\n",
        "      \"- Date and time of interaction\",\n",
        "      \"- Products discussed or quoted (by title)\",\n",
        "      \"- Quote total, discount applied\",\n",
        "      \"- Preferred follow-up channel and time\",\n",
        "      \"- Assigned sales agent or next responsible agent\",\n",
        "      \"Example CRM entry:\",\n",
        "      \"{ 'name': 'Elena Popa', 'contact': '@elenap', 'interested_products': ['CloudShell Rain Jacket', 'Nomad Filter Bottle'], 'quote_total': 160.55, 'discount': '10% new customer', 'followup_method': 'Telegram', 'followup_date': '2025-06-26' }\",\n",
        "      \"CRM logs should use JSON format for easy integration with external systems.\",\n",
        "      \"All entries must include a timestamp and agent signature for traceability.\",\n",
        "      \"Follow-up reminders should be triggered if no action is taken within 24h of quote delivery.\",\n",
        "      \"CRM data supports analytics for customer lifetime value, sales conversion rate, and product interest trends.\"\n",
        "    ]\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "nQgm6uR6vMI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'crewai[tools]'"
      ],
      "metadata": {
        "id": "gWp5KSNQenkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mWa6EPKjet6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Define your agents\n",
        "from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
        "\n",
        "_agents = []\n",
        "_agent_names = []\n",
        "for name, spec in agent_specs.items():\n",
        "    _agent_names.append(name)\n",
        "    _agents.append( Agent(\n",
        "        role=spec[\"role\"],\n",
        "        goal=spec[\"goal\"],\n",
        "        backstory=spec[\"backstory\"],\n",
        "        knowledge_sources=[StringKnowledgeSource(\n",
        "            content=str(spec[\"knowledge\"])\n",
        "        )],\n",
        "        verbose=True,\n",
        "        llm=LLM(model=spec[\"llm\"], base_url=\"http://127.0.0.1:11434\")\n",
        "    ))\n",
        "\n"
      ],
      "metadata": {
        "id": "ujzVu0rzZifz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test agent knowledge retrieval\n",
        "agent = _agents[0]\n",
        "if hasattr(agent, 'knowledge') and agent.knowledge:\n",
        "    test_query = [\"test query\"]\n",
        "    results = agent.knowledge.query(test_query)\n",
        "    print(f\"Agent knowledge results: {len(results)} documents found\")\n",
        "\n",
        "    # Test crew knowledge retrieval (if exists)\n",
        "    if hasattr(crew, 'knowledge') and crew.knowledge:\n",
        "        crew_results = crew.query_knowledge(test_query)\n",
        "        print(f\"Crew knowledge results: {len(crew_results)} documents found\")"
      ],
      "metadata": {
        "id": "7ax2tcmucclF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef6272d6"
      },
      "source": [
        "## Define Tasks\n",
        "Tasks in CrewAI are specific assignments given to agents, detailing the actions they need to perform to achieve a particular goal. Tasks can have dependencies and context, and can be executed asynchronously to ensure an efficient workflow."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Task\n",
        "from textwrap import dedent\n",
        "\n",
        "task_data = [\n",
        "    {\n",
        "        \"description\": \"Welcome a new customer who is planning a hiking trip. Ask engaging questions to understand their travel duration, weather expectations, and gear they already own.\",\n",
        "        \"type\": \"conversation\",\n",
        "        \"complexity\": 2\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"Based on the customer's hiking trip context, recommend a complete gear set including essentials like a backpack, outerwear, and accessories. Justify each suggestion.\",\n",
        "        \"type\": \"recommendation\",\n",
        "        \"complexity\": 4\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"Create a price quote for the recommended products. Apply a 10% first-time customer discount and calculate the final amount with 8% tax. Offer both standard and express shipping.\",\n",
        "        \"type\": \"pricing\",\n",
        "        \"complexity\": 3\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"Log the customer's contact info, travel plans, selected products, quote details, and preferred follow-up method into the CRM in structured JSON format.\",\n",
        "        \"type\": \"data_entry\",\n",
        "        \"complexity\": 2\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"Compose a personalized follow-up message for the customer, summarizing their quote and reminding them of the offer expiration and available delivery options.\",\n",
        "        \"type\": \"followup\",\n",
        "        \"complexity\": 2\n",
        "    }\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "HQdlMcQBZ7L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(prompt):\n",
        "    url = \"http://127.0.0.1:11434/v1/completions\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    data = {\n",
        "        \"prompt\": prompt,\n",
        "        \"model\": \"deepseek-r1:7b\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, data=json.dumps(data))\n",
        "        if response.status_code == 200:\n",
        "            response_data = response.json()\n",
        "            return response_data.get(\"choices\", [{}])[0].get(\"text\", \"\").strip()\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Error: HTTP {response.status_code}\")\n",
        "            print(response.text)\n",
        "            return \"Planner\"  # fallback to a valid agent name\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Request failed: {e}\")\n",
        "        return \"PlannerBot\"\n",
        "\n"
      ],
      "metadata": {
        "id": "9cw-Bd7-poW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " agent_descriptions = \"\\n\".join([\n",
        "    f\"{i+1}. {name}: {spec['goal']}\" for i, (name, spec) in enumerate(agent_specs.items())\n",
        "])\n",
        " print( agent_descriptions)\n"
      ],
      "metadata": {
        "id": "kUSMuOMl-C_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_best_agent(task, agents, llm_func):\n",
        "    agent_descriptions = \"\\n\".join([\n",
        "    f\"{i+1}. {name}: {spec['goal']}\" for i, (name, spec) in enumerate(agent_specs.items())\n",
        "])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a task allocator AI.\n",
        "\n",
        "Your job is to assign the following task to the most appropriate agent based on their expertise.\n",
        "\n",
        "üîß Agent's Goal:\n",
        "\\\"{task['description']}\\\" (Type: {task['type']}, Complexity: {task['complexity']})\n",
        "\n",
        "üß† List of Avaliable Agents:\n",
        "{agent_descriptions}\n",
        "\n",
        "üëâ Your task:\n",
        " Choose one agent from the List of Avaliable Agents, what fit the best with the goal. Respond only with the agent's **name**, exactly as written in th List of Avaliable Agents, this is very important.\n",
        "The format of the response is one word - the agents name. No verbosity, just one name.\n",
        "Example of response:\n",
        "FirstAgent\n",
        "\"\"\"\n",
        "    print(prompt)\n",
        "    response = llm_func(prompt).split(\"</think>\")[1]\n",
        "\n",
        "    return response.strip()\n"
      ],
      "metadata": {
        "id": "3dEPDH2HpwrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Task\n",
        "from textwrap import dedent\n",
        "\n",
        "task_objects = []\n",
        "print (_agent_names)\n",
        "for task in task_data:\n",
        "    selected_name = choose_best_agent(task, agent_specs, get_response)\n",
        "    print(selected_name)\n",
        "    selected_agent = _agents[_agent_names.index(selected_name)]#.get(selected_name, list(agents.values())[0])  # fallback\n",
        "\n",
        "    task_obj = Task(\n",
        "        description=dedent(task[\"description\"]),\n",
        "        expected_output=dedent(f\"Provide a full solution for: {task['description']}\"),\n",
        "        agent=selected_agent\n",
        "    )\n",
        "    task_objects.append(task_obj)\n",
        "    print(f\"‚úÖ Assigned '{task['description']}' to {selected_name}\")\n"
      ],
      "metadata": {
        "id": "o0abHW4cv6Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from crewai.utilities.paths import db_storage_path\n",
        "\n",
        "storage_path = db_storage_path()\n",
        "print(f\"Storage path: {storage_path}\")\n",
        "print(f\"Path exists: {os.path.exists(storage_path)}\")\n",
        "print(f\"Is writable: {os.access(storage_path, os.W_OK) if os.path.exists(storage_path) else 'Path does not exist'}\")\n",
        "\n",
        "# Create with proper permissions\n",
        "if not os.path.exists(storage_path):\n",
        "    os.makedirs(storage_path, mode=0o755, exist_ok=True)\n",
        "    print(f\"Created storage directory: {storage_path}\")"
      ],
      "metadata": {
        "id": "wsOLSZv-75tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from crewai.utilities.paths import db_storage_path\n",
        "\n",
        "# Connect to CrewAI's ChromaDB\n",
        "storage_path = db_storage_path()\n",
        "chroma_path = os.path.join(storage_path, \"knowledge\")\n",
        "\n",
        "if os.path.exists(chroma_path):\n",
        "    client = chromadb.PersistentClient(path=chroma_path)\n",
        "    collections = client.list_collections()\n",
        "\n",
        "    print(\"ChromaDB Collections:\")\n",
        "    for collection in collections:\n",
        "        print(f\"  - {collection.name}: {collection.count()} documents\")\n",
        "else:\n",
        "    print(\"No ChromaDB storage found\")"
      ],
      "metadata": {
        "id": "t6lCzIYv8jMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Crew, Process\n",
        "from crewai import LLM\n",
        "\n",
        "llm = LLM(model=\"ollama/deepseek-r1:7b\", base_url=\"http://127.0.0.1:11434\")\n",
        "crew = Crew(\n",
        "    agents=_agents,\n",
        "    tasks=task_objects,\n",
        "    memory=True,\n",
        "    embedder={\n",
        "        \"provider\": \"ollama\",\n",
        "        \"config\": {\"model\": \"mxbai-embed-large\",\n",
        "                   \"url\": \"http://localhost:11434/api/embeddings\"}\n",
        "    },\n",
        "    process=Process.sequential,\n",
        "    llm=llm\n",
        "\n",
        "\n",
        ")\n",
        "#print(list(agents.values()))\n",
        "result = crew.kickoff()\n",
        "print(\"üß† Final Result:\\n\", result)\n",
        "\n"
      ],
      "metadata": {
        "id": "SnXYdiBDq2YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NONONO Reset specific memory types\n",
        "#crew.reset_memories(command_type='short')     # Short-term memory\n",
        "#crew.reset_memories(command_type='long')      # Long-term memory\n",
        "#crew.reset_memories(command_type='entity')    # Entity memory\n",
        "#crew.reset_memories(command_type='knowledge') # Knowledge storage"
      ],
      "metadata": {
        "id": "JzHsnHSl-z1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "889206a0"
      },
      "outputs": [],
      "source": [
        "# @title üñ•Ô∏è Display the results of your crew as markdown\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "markdown_text = result.raw  # Adjust this based on the actual attribute\n",
        "\n",
        "# Display the markdown content\n",
        "display(Markdown(markdown_text))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}